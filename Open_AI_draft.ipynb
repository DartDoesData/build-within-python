{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DartDoesData/python-practice/blob/main/Open_AI_draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ **Introduction to Large Language Models (LLMs) and OpenAI API**\n",
        "\n",
        "In this lesson, we‚Äôll learn about Large Language Models (LLMs) and explore how to use the OpenAI API. By the end, you'll be able to interact with an AI chatbot, generate structured data, and build fun applications using Python.\n",
        "\n",
        "### Objectives:\n",
        "- Understand what an LLM is and how it works\n",
        "- Learn about the OpenAI API and how to use it with Python\n",
        "- Practice making API requests and handling responses\n",
        "- Build a simple recipe generator using the OpenAI API\n"
      ],
      "metadata": {
        "id": "Eh2xByDwwpBs"
      },
      "id": "Eh2xByDwwpBs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ **What is a Large Language Model (LLM)?**\n",
        "\n",
        "A Large Language Model (LLM) is an AI model trained to understand and generate human language. It learns from vast amounts of text data, making it capable of answering questions, generating text, and even assisting with coding.\n",
        "\n",
        "### Key Use Cases for LLMs:\n",
        "- Answering questions\n",
        "- Summarizing articles\n",
        "- Generating creative content (e.g., stories, dialogue)\n",
        "- Coding assistance (e.g., debugging, code suggestions)\n"
      ],
      "metadata": {
        "id": "KGIg5NBFwpBu"
      },
      "id": "KGIg5NBFwpBu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Ô∏è‚É£ **Overview of the OpenAI API**\n",
        "\n",
        "The OpenAI API allows us to interact with AI models like GPT-4 using a simple request-response model. We send a prompt (input text), and the API returns a response based on the input.\n",
        "\n",
        "### API Documentation:\n",
        "- [OpenAI API Documentation](https://platform.openai.com/docs/introduction)\n",
        "\n",
        "### Available Models:\n",
        "- **GPT-4**: Best for detailed and complex conversations\n",
        "- **GPT-3.5**: Faster and great for general use\n",
        "- **Code models**: Specialized for coding tasks\n"
      ],
      "metadata": {
        "id": "BWRmXCFdwpBu"
      },
      "id": "BWRmXCFdwpBu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ **Setting Up Your OpenAI API Key**\n",
        "To use the OpenAI API, you'll need an API key.\n",
        "\n",
        "### Instructions:\n",
        "1. Create an OpenAI account.\n",
        "2. Go to the [API Key page](https://platform.openai.com/account/api-keys) and generate a new API key.\n",
        "3. Please your API key in Google Colab secrets.\n"
      ],
      "metadata": {
        "id": "Eb36vN-swpBv"
      },
      "id": "Eb36vN-swpBv"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the API key from Colab Secrets\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "if OPENAI_API_KEY:\n",
        "  print('API key retrieved from Colab Secrets.')\n",
        "else:\n",
        "  print('API key not found in Colab Secrets. Please add it under \"Secrets\".')"
      ],
      "metadata": {
        "id": "dkCIhJJ4wpBv"
      },
      "execution_count": null,
      "id": "dkCIhJJ4wpBv",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ **Making Your First OpenAI Request**\n",
        "Let‚Äôs make our first request to OpenAI‚Äôs API using Python.\n",
        "\n",
        "### Exercise:\n",
        "- Send a simple prompt ('Hello, world!') and view the response."
      ],
      "metadata": {
        "id": "1KCnHX3_wpBw"
      },
      "id": "1KCnHX3_wpBw"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "MAX_TOKENS = 1024\n",
        "\n",
        "# Define the correct API endpoint and headers\n",
        "url = 'https://api.openai.com/v1/chat/completions'\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {OPENAI_API_KEY}',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# This is what you want to ask the LLM\n",
        "openai_prompt = input('What would you like to ask? ')\n",
        "\n",
        "# Prepare the data for the chat completion request\n",
        "data = {\n",
        "    'model': 'gpt-3.5-turbo',  # Use 'gpt-3.5-turbo'\n",
        "    'messages': [\n",
        "        {'role': 'user', 'content': openai_prompt}\n",
        "    ],\n",
        "    'max_tokens': MAX_TOKENS # TODO[DDW] change to global var\n",
        "}\n",
        "\n",
        "# Send the POST request\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "# Check the response status and print the result\n",
        "if response.status_code == 200:\n",
        "    response_data = response.json()\n",
        "    message = response_data['choices'][0]['message']['content'].strip()\n",
        "    print(message)\n",
        "else:\n",
        "    print(f'Error: {response.status_code} - {response.text}')\n"
      ],
      "metadata": {
        "id": "rvhKLPsowpBw"
      },
      "execution_count": null,
      "id": "rvhKLPsowpBw",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5Ô∏è‚É£ **Activity: Multi-Item Prompt and Structured Storage**\n",
        "Let‚Äôs prompt OpenAI with a list of items and store the responses.\n",
        "\n",
        "### Exercise:\n",
        "- Prompt for a list of cybersecurity terms and save the responses in a DataFrame."
      ],
      "metadata": {
        "id": "I5euWY3kwpBw"
      },
      "id": "I5euWY3kwpBw"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of cybersecurity terms\n",
        "terms = ['phishing', 'malware', 'ransomware']\n",
        "responses = []\n",
        "\n",
        "# Loop through the terms and get responses\n",
        "for term in terms:\n",
        "    data = {\n",
        "        'model': 'gpt-3.5-turbo',\n",
        "        'messages': [\n",
        "            {'role': 'user', 'content': f'Explain {term}'}\n",
        "        ],\n",
        "        'max_tokens': MAX_TOKENS\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "    # Check for successful response\n",
        "    if response.status_code == 200:\n",
        "        response_json = response.json()\n",
        "        explanation = response_json['choices'][0]['message']['content'].strip()\n",
        "        responses.append({'term': term, 'explanation': explanation})\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code} - {response.text}\")\n",
        "        responses.append({'term': term, 'explanation': 'Error fetching explanation'})\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(responses)\n",
        "display(df.head())"
      ],
      "metadata": {
        "id": "_TiAb0uLwpBw"
      },
      "execution_count": null,
      "id": "_TiAb0uLwpBw",
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO [DDW] explain json preview\n",
        "\n",
        "response_json"
      ],
      "metadata": {
        "id": "NsAvrft_z8og"
      },
      "id": "NsAvrft_z8og",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO [DDW] explain how to parse response\n",
        "responses"
      ],
      "metadata": {
        "id": "HwlWfcADz2lj"
      },
      "id": "HwlWfcADz2lj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6Ô∏è‚É£ **Recipe Generator Activity**\n",
        "Build a simple recipe generator using the OpenAI API.\n",
        "\n",
        "### Exercise:\n",
        "- Prompt OpenAI with a meal name (e.g., 'Pasta Carbonara') and return a JSON with the ingredients.\n",
        "- Parse the ingredients into a DataFrame with columns: `item`, `quantity`, `measurement`, `unit`."
      ],
      "metadata": {
        "id": "WHytBAY1wpBx"
      },
      "id": "WHytBAY1wpBx"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Accept dish input from the user\n",
        "meal = input(\"Enter the name of the dish: \")\n",
        "\n",
        "# Prepare the request data\n",
        "data = {\n",
        "    'model': 'gpt-3.5-turbo',\n",
        "    'messages': [\n",
        "        {'role': 'user', 'content': f'Provide a recipe for {meal} in JSON format with ingredients.'}\n",
        "    ],\n",
        "    'max_tokens': MAX_TOKENS\n",
        "}\n",
        "\n",
        "# Send the request\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "# Check for a successful response\n",
        "if response.status_code == 200:\n",
        "    response_json = response.json()\n",
        "    recipe_text = response_json['choices'][0]['message']['content'].strip()\n",
        "    print(\"Recipe Response:\\n\", recipe_text)\n",
        "\n",
        "    # Try to parse the JSON response\n",
        "    try:\n",
        "        recipe_data = json.loads(recipe_text)\n",
        "        # TODO[DDW] Set up activity/explanation for this\n",
        "        ingredients = recipe_data['ingredients']\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: The response could not be parsed as JSON. Please check the output format.\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code} - {response.text}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zeu4toQawpBx"
      },
      "execution_count": null,
      "id": "zeu4toQawpBx",
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame\n",
        "ingredients_df = pd.DataFrame(ingredients)\n",
        "display(ingredients_df)\n"
      ],
      "metadata": {
        "id": "v8OEt2XG2mIl"
      },
      "id": "v8OEt2XG2mIl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fllY8SvV07AA"
      },
      "id": "fllY8SvV07AA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}