{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DartDoesData/build-within-python/blob/main/Week_5/Week_5_Day_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ **Introduction to Large Language Models (LLMs) and OpenAI API**\n",
        "\n",
        "In this lesson, we‚Äôll learn about Large Language Models (LLMs) and explore how to use the OpenAI API. By the end, you'll be able to interact with an AI chatbot, generate structured data, and build fun applications using Python.\n",
        "\n",
        "### Objectives:\n",
        "- Understand what an LLM is and how it works\n",
        "- Learn about the OpenAI API and how to use it with Python\n",
        "- Practice making API requests and handling responses\n",
        "- Build a simple recipe generator using the OpenAI API\n"
      ],
      "metadata": {
        "id": "Eh2xByDwwpBs"
      },
      "id": "Eh2xByDwwpBs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ **What is a Large Language Model (LLM)?**\n",
        "\n",
        "A Large Language Model (LLM) is an AI model trained to understand and generate human language. It learns from vast amounts of text data, making it capable of answering questions, generating text, and even assisting with coding.\n",
        "\n",
        "### Key Use Cases for LLMs:\n",
        "- Answering questions\n",
        "- Summarizing articles\n",
        "- Generating creative content (e.g., stories, dialogue)\n",
        "- Coding assistance (e.g., debugging, code suggestions)\n"
      ],
      "metadata": {
        "id": "KGIg5NBFwpBu"
      },
      "id": "KGIg5NBFwpBu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Ô∏è‚É£ **Overview of the OpenAI API**\n",
        "\n",
        "The OpenAI API allows us to interact with AI models like GPT-4 using a simple request-response model. We send a prompt (input text), and the API returns a response based on the input.\n",
        "\n",
        "### API Documentation:\n",
        "- [OpenAI API Documentation](https://platform.openai.com/docs/introduction)\n",
        "\n",
        "### Available Models:\n",
        "- **GPT-4**: Best for detailed and complex conversations\n",
        "- **GPT-3.5**: Faster and great for general use\n",
        "- **Code models**: Specialized for coding tasks\n"
      ],
      "metadata": {
        "id": "BWRmXCFdwpBu"
      },
      "id": "BWRmXCFdwpBu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ **Setting Up Your OpenAI API Key**\n",
        "To use the OpenAI API, you'll need an API key.\n",
        "\n",
        "### Instructions:\n",
        "1. Create an OpenAI account.\n",
        "2. Go to the [API Key page](https://platform.openai.com/account/api-keys) and generate a new API key.\n",
        "3. Please your API key in Google Colab secrets.\n"
      ],
      "metadata": {
        "id": "Eb36vN-swpBv"
      },
      "id": "Eb36vN-swpBv"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve the API key from Colab Secrets\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "if OPENAI_API_KEY:\n",
        "  print('API key retrieved from Colab Secrets.')\n",
        "else:\n",
        "  print('API key not found in Colab Secrets. Please add it under \"Secrets\".')"
      ],
      "metadata": {
        "id": "dkCIhJJ4wpBv"
      },
      "execution_count": null,
      "id": "dkCIhJJ4wpBv",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ **Making Your First OpenAI Request**\n",
        "Let‚Äôs make our first request to OpenAI‚Äôs API using Python.\n",
        "\n",
        "### Exercise:\n",
        "- Send a simple prompt and view the response."
      ],
      "metadata": {
        "id": "1KCnHX3_wpBw"
      },
      "id": "1KCnHX3_wpBw"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Define the maximum number of tokens for the LLM response\n",
        "MAX_TOKENS = 1024\n",
        "\n",
        "# Define the API endpoint and headers\n",
        "openai_endpoint = 'https://api.openai.com/v1/chat/completions'\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {OPENAI_API_KEY}',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# Get user input for the prompt\n",
        "user_input = input('What would you like to ask the LLM? ')\n",
        "\n",
        "# TODO [DDW] explain payload\n",
        "# Prepare the request payload\n",
        "request_payload = {\n",
        "    'model': 'gpt-3.5-turbo',\n",
        "    'messages': [\n",
        "        {'role': 'user', 'content': user_input}\n",
        "    ],\n",
        "    'max_tokens': MAX_TOKENS\n",
        "}\n",
        "\n",
        "# Send the POST request to the API\n",
        "response = requests.post(openai_endpoint, headers=headers, json=request_payload)\n",
        "\n",
        "# Check the response status and process the result\n",
        "if response.status_code == 200:\n",
        "    response_json = response.json()\n",
        "    llm_response_text = response_json['choices'][0]['message']['content'].strip()\n",
        "    print(llm_response_text)\n",
        "else:\n",
        "    print(f'Error: {response.status_code} - {response.text}')\n"
      ],
      "metadata": {
        "id": "rvhKLPsowpBw"
      },
      "execution_count": null,
      "id": "rvhKLPsowpBw",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activity 1: Extracting the OpenAI Response\n",
        "\n",
        "### üìù **Overview:**\n",
        "In this activity, you'll learn how to send a request to the OpenAI API and **extract the response text**. The focus here is on understanding how to access the JSON data returned by the API.\n",
        "\n",
        "### **Instructions:**\n",
        "1. Review the starter code below.\n",
        "2. Send a request to the OpenAI API using a simple prompt.\n",
        "3. Extract the response text from the JSON data and store it in a variable called `llm_response_text`.\n",
        "4. Print the response text to see the output.\n",
        "\n",
        "### **Task:**\n",
        "- Run the code and try asking a question like \"What is Python programming?\".\n",
        "- Extract the text response and store it in `llm_response_text`.\n",
        "- Print the variable to see the response.\n",
        "\n",
        "**üí° Tip:** Use the `response.json()` method to convert the response to a dictionary and access the content with `response_json['choices'][0]['message']['content'].strip()`."
      ],
      "metadata": {
        "id": "hf_56trPU2GF"
      },
      "id": "hf_56trPU2GF"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "# Define the maximum number of tokens\n",
        "MAX_TOKENS = 1024\n",
        "\n",
        "# Define the API endpoint and headers\n",
        "openai_endpoint = 'https://api.openai.com/v1/chat/completions'\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {OPENAI_API_KEY}',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# Get user input for the prompt\n",
        "user_input = input('Ask the LLM anything: ')\n",
        "\n",
        "# Prepare the request payload\n",
        "request_payload = {\n",
        "    'model': 'gpt-3.5-turbo',\n",
        "    'messages': [\n",
        "        {'role': 'user', 'content': user_input}\n",
        "    ],\n",
        "    'max_tokens': MAX_TOKENS\n",
        "}\n",
        "\n",
        "# Send the POST request to the API\n",
        "response = requests.post(openai_endpoint, headers=headers, json=request_payload)\n",
        "\n",
        "# TODO: Extract the response text and store it in a variable called `llm_response`\n",
        "# HINT: Look inside the JSON response for the 'choices' key\n",
        "\n",
        "# Print the extracted response\n",
        "print() # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "1-ywvJxxVIUv"
      },
      "id": "1-ywvJxxVIUv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activity 2: Looping Through Multiple Prompts and Storing Responses\n",
        "\n",
        "### üìù **Overview:**\n",
        "In this activity, you'll learn how to send multiple prompts to the OpenAI API in a loop and store the responses in a list of dictionaries. Then, you'll convert this list to a Pandas DataFrame for easy analysis.\n",
        "\n",
        "### **Instructions:**\n",
        "1. Review the starter code below.\n",
        "2. Use a loop to send multiple prompts (cybersecurity terms) to the OpenAI API.\n",
        "3. Extract the response for each term and store it in a list of dictionaries with `term` and `explanation`.\n",
        "4. Convert the list to a DataFrame and display the results.\n",
        "\n",
        "### **Starter Code:**\n",
        "\n",
        "```python\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Define the maximum number of tokens\n",
        "MAX_TOKENS = 1024\n",
        "\n",
        "# Define the API endpoint and headers\n",
        "openai_endpoint = 'https://api.openai.com/v1/chat/completions'\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {OPENAI_API_KEY}',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "# List of cybersecurity terms\n",
        "terms = ['phishing', 'malware', 'ransomware']\n",
        "responses = []\n",
        "\n",
        "# Loop through the terms and get responses\n",
        "for term in terms:\n",
        "    # Prepare the request payload\n",
        "    request_payload = # YOUR CODE HERE\n",
        "\n",
        "    # Send the POST request\n",
        "    response = # YOUR CODE HERE\n",
        "\n",
        "    # Check for a successful response\n",
        "    if response.status_code == 200:\n",
        "        # YOUR CODE HERE\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code} - {response.text}\")\n",
        "        responses.append({'term': term, 'explanation': 'Error fetching explanation'})\n",
        "\n",
        "# Convert the responses to a DataFrame\n",
        "response_df = pd.DataFrame(responses)\n",
        "print(\"Here are your explanations:\")\n",
        "display(response_df.head())\n",
        "```\n",
        "\n",
        "### **Task:**\n",
        "1. Loop through the list of cybersecurity terms (`phishing`, `malware`, `ransomware`).\n",
        "2. Send each term as a prompt to the API and extract the explanation.\n",
        "3. Store the term and its explanation in the `responses` list as a dictionary (`{'term': term, 'explanation': explanation}`).\n",
        "4. Convert the list of responses to a Pandas DataFrame and display the DataFrame.\n",
        "\n",
        "### **Reflection:**\n",
        "- What insights can you gather by looking at the explanations for each cybersecurity term?\n",
        "- How might you use this approach to build a glossary or FAQ bot?\n",
        "\n",
        "---\n",
        "\n",
        "**üí° Pro Tip:** If you want to add more terms, simply extend the `terms` list with additional topics like `\"spyware\"`, `\"adware\"`, or `\"keylogging\"`."
      ],
      "metadata": {
        "id": "vNFXWCf9VUYr"
      },
      "id": "vNFXWCf9VUYr"
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "K2sujaKhVvBI"
      },
      "id": "K2sujaKhVvBI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Recipe Generator Activity**\n",
        "Build a simple recipe generator using the OpenAI API.\n",
        "\n",
        "### Exercise:\n",
        "- Prompt OpenAI with a meal name (e.g., 'Pasta Carbonara') and return a JSON with the ingredients.\n",
        "- Parse the ingredients into a DataFrame with columns: `item`, `quantity`, `measurement`, `unit`."
      ],
      "metadata": {
        "id": "WHytBAY1wpBx"
      },
      "id": "WHytBAY1wpBx"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Accept dish input from the user\n",
        "meal = input(\"Enter the name of the dish: \")\n",
        "\n",
        "# Define endpoint\n",
        "openai_endpoint = 'https://api.openai.com/v1/chat/completions'\n",
        "\n",
        "# Prepare the request data\n",
        "data = {\n",
        "    'model': 'gpt-3.5-turbo',\n",
        "    'messages': [\n",
        "        {'role': 'user', 'content': f'Provide a recipe for {meal} in JSON format with ingredients.'}\n",
        "    ],\n",
        "    'max_tokens': MAX_TOKENS\n",
        "}\n",
        "\n",
        "# Send the request\n",
        "response = requests.post(openai_endpoint, headers=headers, json=data)\n",
        "\n",
        "# Check for a successful response\n",
        "if response.status_code == 200:\n",
        "    response_json = response.json()\n",
        "    recipe_text = response_json['choices'][0]['message']['content'].strip()\n",
        "    print(\"Recipe Response:\\n\", recipe_text)\n",
        "\n",
        "    # Try to parse the JSON response\n",
        "    try:\n",
        "        recipe_data = json.loads(recipe_text)\n",
        "        ingredients = recipe_data['ingredients']\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: The response could not be parsed as JSON. Please check the output format.\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code} - {response.text}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zeu4toQawpBx"
      },
      "execution_count": null,
      "id": "zeu4toQawpBx",
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EVERYONE DO\n",
        "\n",
        "# Create a DataFrame from the recipes\n",
        "# List out the instructions in an ordered list"
      ],
      "metadata": {
        "id": "v8OEt2XG2mIl"
      },
      "id": "v8OEt2XG2mIl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "fllY8SvV07AA"
      },
      "id": "fllY8SvV07AA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}